---
title: "Practical: Unimodal response models in gllvm "
subtitle: "Physalia workshop on GLLVMs"
author: "Bert van der Veen"
output: html_document
---

# Description

If a response model is truly unimodal, fitting a linear model will poorly retrieve the latent variables, and can lead to poor estimation of species associations. That is something community ecologists have understood for decades, because it is a subject that has been at the basis of choosing an ordination method. 

However, there has been no ordination methods that actually implement a unimodal response model. NMDS gained in popularity as it is said to be "robust" to the response model, but the only reason for that is because it completely ignores any species-specific information. That makes it a poor ordination method if you are interested in species, which we usually are in community ecology.

In <tt>gllvm</tt> we can truely implement an ordination where species respond quadratically to the latent variables. We explicitly estimate species' optima, and we estimate species' tolerances. This makes it the most complex ordination method for community ecology to date, and it is that complexity that keeps it from being suitable to all datasets; it is a little bit more "data hungry" than an ordination method with a linear response model.

In this practical, we will apply the first ordination method that is explicitly based on a unimodal response model.

# Part I

Here, I will work with the wadden data. The mathematics for implementing the unimodal response model is very complex, and we have yet to figure out how to do it for beta responses (i.e., that is the only not supported response type for this model in the package). Hence, we cannot continue with the data from the last exercise.

```{r data}
Y <- read.table("../../data/waddenY.csv", sep="," ,header=TRUE, row.names = 2)[,-1]
```

The model is fitted similarly as before, but instead we add the "quadratic" argument which takes the options TRUE, "LV", and FALSE. As covered in the lecture, these correspond to assuming species-specific (TRUE) and species-common ("LV") tolerances, while FALSE corresponds to equal or common tolerances only if we use a random row effect at the same level as the ordination (`row.eff = "random"` if the ordination is specified as random effect and at the observation-level, `row.eff = "fixed"` for a observation-level ordination with fixed effects).

Because the model is more complex, so it also takes longer to fit it. I will fit it straight away with a negative-binomial distribution, since that was is also what this dataset required in the last exercise. We could also just include more latent variables, because that has a similar effect of accounting for residual variation (just within the model, instead of in the distribution). One thing to really keep in mind, is the increased complexity of the unimodal response model, i.e., there are more parameters to estimate, for which there needs to be enough information in the data. 

```{r uo, cache = TRUE, message=FALSE}
library(gllvm)
TMB::openmp(parallel::detectCores()-1, autopar = TRUE, DLL = "gllvm")
model1 <- gllvm(Y, num.lv = 2, quadratic = TRUE, n.init = 3, family = "negative.binomial", disp.formula = rep(1, ncol(Y)))
gllvm::ordiplot(model1, biplot = TRUE)
```

The `n.init` option is very necessary: the GLLVM with unimodal response is even more prone to finding a suboptimal solution than usually. That also means that fitting the model is much slower, so using <tt> gllvm</tt> its (new) option for parallel computation could help. `ordiplot` will plot the species optima, and if the optima are too far away from the estimated latent variable, it will plot the species effects as arrows instead.

```{r uo2, message=FALSE, results="hide", echo = -1}
library(gllvm)
ordiplot(model1, biplot = TRUE)
```

Clearly, the optima are far away from the gradient, which means that on one of the latent variables we are estimating linear responses instead of unimodal responses: so we have one long and one short gradient. Let's inspect the optima

```{r opt}
optima(model1, sd.errors = FALSE)
```

and the tolerances

```{r tol}
tolerances(model1, sd.errors = FALSE)
```

manually. As expected, some optima and tolerances are very large, indicating that a few species respond linearly to the latent variable rather than unimodally. Predicting with the model might make this a little easier to visualize, so let's do that.

```{r pred, results = "hide", echo = -1, fig.height = 10, fig.width = 10}
par(mfrow=c(2,1))
LVs = getLV(model1)
newLV = cbind(LV1 = seq(min(LVs[,1]), max(LVs[,1]), length.out=1000), LV2 = 0)
preds <- predict(model1, type = "response", newLV = newLV)
plot(NA, ylim = range(preds), xlim = c(range(getLV(model1))), ylab  = "Predicted response", xlab = "LV1")
segments(x0=optima(model1, sd.errors = FALSE)[,1],x1 = optima(model1, sd.errors = FALSE)[,1], y0 = rep(0, ncol(model1$y)), y1 = apply(preds,2,max), col = "red", lty = "dashed", lwd = 2)
rug(getLV(model1)[,1])
sapply(1:ncol(model1$y), function(j)lines(sort(newLV[,1]), preds[order(newLV[,1]),j], lwd = 2))

newLV = cbind(LV1 = 0, LV2 =  seq(min(LVs[,2]), max(LVs[,2]), length.out=1000))
preds <- predict(model1, type = "response", newLV = newLV)
plot(NA, ylim = range(preds), xlim = c(range(getLV(model1))), ylab  = "Predicted response", xlab = "LV2")
segments(x0=optima(model1, sd.errors = FALSE)[,2],x1 = optima(model1, sd.errors = FALSE)[,2], y0 = rep(0, ncol(model1$y)), y1 = apply(preds,2,max), col = "red", lty = "dashed", lwd = 2)
rug(getLV(model1)[,2])
sapply(1:ncol(model1$y), function(j)lines(sort(newLV[,2]), preds[order(newLV[,2]),j], lwd = 2))
```

We can also calculate turnover for these two estimated gradients, although that is a little difficult when we have unequal tolerances.

```{r grad_length}
# Extract tolerances
tol <- tolerances(model1, sd.errors = FALSE)
gradLength <- 4/apply(tol, 2, median)
```

```{r grad_length_res}
cat("Gradient length:", gradLength)
```

As expected, the second gradient is -very- short; we might even be able to drop it from the model. Let's have a look:

```{r compare}
model2<-update(model1, num.lv=1)
AIC(model1, model2)
BIC(model1, model2)
```

It depends on how you look at it. We can just stick with the same model for now. Finally, we can calculate the median turnover:

```{r turn}
turn <- 2*qnorm(.999, sd = apply(tol, 2, median))
cat("Turnover rate:", turn)
```

and as expected, turnover is slow on the second latent variable, as also reflected by the short gradient length.

## Tasks I

1. Fit the model with species-specific tolerances and go through the code.
2. Also try fitting a model with species-common tolerances, a model without quadratic responses, and a model with `row.eff`.
3. Compare the ordinations, are the estimated latent variables very different? You can do this via the `procrustes` function as demonstrated in the first practical today, or via `cor`.
4. Use information criteria, or hypothesis testing, to determine which model is best.
5. Add covariates into the ordination of the quadratic response model with `lv.formula`, `num.RR` or `num.lv.c` and perhaps the random effects formulation with `randomB``